[
    {
        "title": ": Democratized LLM Scaling for A Large Model Zoo in the Wild",
        "citation": "The Thirty-eight Conference on Neural Information Processing Systems …, 0",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:u_35RYKgDlwC"
    },
    {
        "title": "A tale of two efficient and informative negative sampling distributions",
        "pub_year": "2021",
        "citation": "International conference on machine learning, 2319-2329, 2021",
        "num_citations": 11,
        "author_pub_id": "jCNJhFcAAAAJ:3fE2CSJIrl8C"
    },
    {
        "title": "A tuning-free asymmetric 2bit quantization for kv cache",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2402.02750, 2024",
        "num_citations": 40,
        "author_pub_id": "jCNJhFcAAAAJ:g5m5HwL7SMYC"
    },
    {
        "title": "Analyzing log analysis: An empirical study of user log mining",
        "pub_year": "2014",
        "citation": "28th Large Installation System Administration Conference (LISA14), 62-77, 2014",
        "num_citations": 71,
        "author_pub_id": "jCNJhFcAAAAJ:u5HHmVD_uO8C"
    },
    {
        "title": "Angular visual hardness",
        "pub_year": "2020",
        "citation": "International Conference on Machine Learning, 1637-1648, 2020",
        "num_citations": 52,
        "author_pub_id": "jCNJhFcAAAAJ:WF5omc3nYNoC"
    },
    {
        "title": "Anima Anandkumar, and Yuandong Tian",
        "pub_year": "2024",
        "citation": "Galore: Memory-efficient LLM training by gradient low-rank projection. CoRR …, 2024",
        "num_citations": 25,
        "author_pub_id": "jCNJhFcAAAAJ:dfsIfKJdRG4C"
    },
    {
        "title": "Anima Anandkumar, and Yuandong Tian. Galore: Memory-efficient llm training by gradient low-rank projection",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2403.03507, 2024",
        "num_citations": 48,
        "author_pub_id": "jCNJhFcAAAAJ:M05iB0D1s5AC"
    },
    {
        "title": "BearLoc: a composable distributed framework for indoor localization systems",
        "pub_year": "2015",
        "citation": "Proceedings of the 2015 Workshop on IoT challenges in Mobile and Industrial …, 2015",
        "num_citations": 7,
        "author_pub_id": "jCNJhFcAAAAJ:u-x6o8ySG0sC"
    },
    {
        "title": "Cocktailsgd: Fine-tuning foundation models over 500mbps networks",
        "pub_year": "2023",
        "citation": "International Conference on Machine Learning, 36058-36076, 2023",
        "num_citations": 35,
        "author_pub_id": "jCNJhFcAAAAJ:-f6ydRqryjwC"
    },
    {
        "title": "Decentralized training of foundation models in heterogeneous environments",
        "pub_year": "2022",
        "citation": "Neural Information Processing Systems., 2022",
        "num_citations": 86,
        "author_pub_id": "jCNJhFcAAAAJ:aqlVkmm33-oC"
    },
    {
        "title": "Deja vu: Contextual sparsity for efficient llms at inference time",
        "pub_year": "2023",
        "citation": "International Conference on Machine Learning, 22137-22176, 2023",
        "num_citations": 233,
        "author_pub_id": "jCNJhFcAAAAJ:IWHjjKOFINEC"
    },
    {
        "title": "Densified winner take all (WTA) hashing for sparse datasets",
        "pub_year": "2018",
        "citation": "Uncertainty in artificial intelligence, 2018",
        "num_citations": 25,
        "author_pub_id": "jCNJhFcAAAAJ:Y0pCki6q_DkC"
    },
    {
        "title": "Efficient Streaming Language Models with Attention Sinks. arXiv (2023)",
        "pub_year": "2023",
        "citation": "",
        "num_citations": 8,
        "author_pub_id": "jCNJhFcAAAAJ:fPk4N6BV_jEC"
    },
    {
        "title": "Efficient streaming language models with attention sinks",
        "pub_year": "2023",
        "citation": "arXiv preprint arXiv:2309.17453, 2023",
        "num_citations": 364,
        "author_pub_id": "jCNJhFcAAAAJ:TQgYirikUcIC"
    },
    {
        "title": "Fast algorithms for a new relaxation of optimal transport",
        "pub_year": "2023",
        "citation": "The Thirty Sixth Annual Conference on Learning Theory, 4831-4862, 2023",
        "num_citations": 5,
        "author_pub_id": "jCNJhFcAAAAJ:mB3voiENLucC"
    },
    {
        "title": "Fast and accurate stochastic gradient estimation",
        "pub_year": "2019",
        "citation": "Advances in Neural Information Processing Systems 32, 2019",
        "num_citations": 53,
        "author_pub_id": "jCNJhFcAAAAJ:ufrVoPGSRksC"
    },
    {
        "title": "Federated Black-box Prompt Tuning System for Large Language Models on the Edge",
        "pub_year": "2024",
        "citation": "Proceedings of the 30th Annual International Conference on Mobile Computing …, 2024",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:4OULZ7Gr8RgC"
    },
    {
        "title": "Fine-tuning language models over slow networks using activation compression with guarantees",
        "pub_year": "2022",
        "citation": "arXiv preprint arXiv:2206.01299, 2022",
        "num_citations": 19,
        "author_pub_id": "jCNJhFcAAAAJ:qxL8FJ1GzNcC"
    },
    {
        "title": "FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU",
        "pub_year": "2023",
        "citation": "International Conference on Machine Learning, 2023",
        "num_citations": 319,
        "author_pub_id": "jCNJhFcAAAAJ:L8Ckcad2t8MC"
    },
    {
        "title": "Found in the middle: How language models use long contexts better via plug-and-play positional encoding",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2403.04797, 2024",
        "num_citations": 16,
        "author_pub_id": "jCNJhFcAAAAJ:maZDTaKrznsC"
    },
    {
        "title": "Galore: Memory-efficient llm training by gradient low-rank projection",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2403.03507, 2024",
        "num_citations": 38,
        "author_pub_id": "jCNJhFcAAAAJ:isC4tDSrTZIC"
    },
    {
        "title": "Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2402.09398, 2024",
        "num_citations": 4,
        "author_pub_id": "jCNJhFcAAAAJ:r0BpntZqJG4C"
    },
    {
        "title": "H  O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models",
        "pub_year": "2023",
        "citation": "International Conference on Machine Learning, 2023",
        "num_citations": 236,
        "author_pub_id": "jCNJhFcAAAAJ:hC7cP41nSMkC"
    },
    {
        "title": "Halos: Hashing large output space for cheap inference",
        "pub_year": "2022",
        "citation": "Proceedings of Machine Learning and Systems 4, 110-125, 2022",
        "num_citations": 9,
        "author_pub_id": "jCNJhFcAAAAJ:M3ejUd6NZC8C"
    },
    {
        "title": "HexGen: Generative Inference of Large Language Model over Heterogeneous Environment",
        "citation": "Forty-first International Conference on Machine Learning, 0",
        "num_citations": 9,
        "author_pub_id": "jCNJhFcAAAAJ:ns9cj8rnVeAC"
    },
    {
        "title": "IFMoE: An Inference Framework Design for Fine-grained MoE",
        "citation": "",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:zA6iFVUQeVQC"
    },
    {
        "title": "Inrank: Incremental low-rank learning",
        "pub_year": "2023",
        "citation": "arXiv preprint arXiv:2306.11250, 2023",
        "num_citations": 9,
        "author_pub_id": "jCNJhFcAAAAJ:ZeXyd9-uunAC"
    },
    {
        "title": "Joma: Demystifying multilayer transformers via joint dynamics of mlp and attention",
        "pub_year": "2023",
        "citation": "arXiv preprint arXiv:2310.00535, 2023",
        "num_citations": 41,
        "author_pub_id": "jCNJhFcAAAAJ:R3hNpaxXUhUC"
    },
    {
        "title": "KIVI: Plug-and-play 2bit KV Cache Quantization with Streaming Asymmetric Quantization",
        "pub_year": "2024",
        "citation": "",
        "num_citations": 44,
        "author_pub_id": "jCNJhFcAAAAJ:RHpTSmoSYBkC"
    },
    {
        "title": "Laughing hyena distillery: Extracting compact recurrences from convolutions",
        "pub_year": "2024",
        "citation": "Advances in Neural Information Processing Systems 36, 2024",
        "num_citations": 20,
        "author_pub_id": "jCNJhFcAAAAJ:e5wmG9Sq2KIC"
    },
    {
        "title": "Layer skip: Enabling early exit inference and self-speculative decoding",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2404.16710, 2024",
        "num_citations": 41,
        "author_pub_id": "jCNJhFcAAAAJ:NMxIlDl6LWMC"
    },
    {
        "title": "Learn to be efficient: Build structured sparsity in large language models",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2402.06126, 2024",
        "num_citations": 10,
        "author_pub_id": "jCNJhFcAAAAJ:j3f4tGmQtD8C"
    },
    {
        "title": "Llm inference unveiled: Survey and roofline model insights",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2402.16363, 2024",
        "num_citations": 47,
        "author_pub_id": "jCNJhFcAAAAJ:bEWYMUwI8FkC"
    },
    {
        "title": "LoCoCo: Dropping In Convolutions for Long Context Compression",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2406.05317, 2024",
        "num_citations": 3,
        "author_pub_id": "jCNJhFcAAAAJ:NaGl4SEjCO4C"
    },
    {
        "title": "Locality Sensitive Sampling for Extreme-Scale Optimization and Deep Learning",
        "pub_year": "2020",
        "citation": "Rice University, 2020",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:UebtZRa9Y70C"
    },
    {
        "title": "Locality sensitive teaching",
        "pub_year": "2021",
        "citation": "Advances in Neural Information Processing Systems 34, 18049-18062, 2021",
        "num_citations": 19,
        "author_pub_id": "jCNJhFcAAAAJ:KlAtU1dfN6UC"
    },
    {
        "title": "MINI-SEQUENCE TRANSFORMER: Optimizing Intermediate Memory for Long Sequences Training",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2407.15892, 2024",
        "num_citations": 1,
        "author_pub_id": "jCNJhFcAAAAJ:vV6vV6tmYwMC"
    },
    {
        "title": "MONGOOSE: A learnable LSH framework for efficient neural network training",
        "pub_year": "2021",
        "citation": "International Conference on Learning Representations, 2021",
        "num_citations": 79,
        "author_pub_id": "jCNJhFcAAAAJ:8k81kl-MbHgC"
    },
    {
        "title": "Magicdec: Breaking the latency-throughput tradeoff for long context generation with speculative decoding",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2408.11049, 2024",
        "num_citations": 6,
        "author_pub_id": "jCNJhFcAAAAJ:70eg2SAEIzsC"
    },
    {
        "title": "Magicpig: Lsh sampling for efficient llm generation",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2410.16179, 2024",
        "num_citations": 3,
        "author_pub_id": "jCNJhFcAAAAJ:pqnbT2bcN3wC"
    },
    {
        "title": "Megalodon: Efficient llm pretraining and inference with unlimited context length",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2404.08801, 2024",
        "num_citations": 21,
        "author_pub_id": "jCNJhFcAAAAJ:blknAaTinKkC"
    },
    {
        "title": "Memory Mosaics",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2405.06394, 2024",
        "num_citations": 3,
        "author_pub_id": "jCNJhFcAAAAJ:35N4QoGY0k4C"
    },
    {
        "title": "Model-GLUE: Democratized LLM Scaling for A Large Model Zoo in the Wild",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2410.05357, 2024",
        "num_citations": 1,
        "author_pub_id": "jCNJhFcAAAAJ:rO6llkc54NcC"
    },
    {
        "title": "Monarch: Expressive structured matrices for efficient and accurate training",
        "pub_year": "2022",
        "citation": "International Conference on Machine Learning, 4690-4721, 2022",
        "num_citations": 91,
        "author_pub_id": "jCNJhFcAAAAJ:4TOpqqG69KYC"
    },
    {
        "title": "Nearest Neighbor Speculative Decoding for LLM Generation and Attribution",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2405.19325, 2024",
        "num_citations": 6,
        "author_pub_id": "jCNJhFcAAAAJ:YFjsv_pBGBYC"
    },
    {
        "title": "On the Surprising Effectiveness of Attention Transfer for Vision Transformers",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2411.09702, 2024",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:3s1wT3WcHBgC"
    },
    {
        "title": "Pixelated butterfly: Simple and efficient sparse training for neural network models",
        "pub_year": "2022",
        "citation": "International Conference on Learning Representations, 2022",
        "num_citations": 81,
        "author_pub_id": "jCNJhFcAAAAJ:YOwf2qJgpHMC"
    },
    {
        "title": "Prompt-prompted Mixture of Experts for Efficient LLM Generation",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2404.01365, 2024",
        "num_citations": 6,
        "author_pub_id": "jCNJhFcAAAAJ:JV2RwH3_ST0C"
    },
    {
        "title": "Q-Hitter: A Better Token Oracle for Efficient LLM Inference via Sparse-Quantized KV Cache",
        "pub_year": "2024",
        "citation": "Proceedings of Machine Learning and Systems 6, 381-394, 2024",
        "num_citations": 12,
        "author_pub_id": "jCNJhFcAAAAJ:BqipwSGYUEgC"
    },
    {
        "title": "SFT: Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2412.06289, 2024",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:SeFeTyx0c_EC"
    },
    {
        "title": "SLIDE: In Defense of Smart Algorithms over Hardware Acceleration for Large-scale Deep Learning Systems",
        "pub_year": "2020",
        "citation": "Proceedings of Machine Learning and System 2, 291--306, 2020",
        "num_citations": 143,
        "author_pub_id": "jCNJhFcAAAAJ:YsMSGLbcyi4C"
    },
    {
        "title": "SOLAR: Sparse Orthogonal Learned and Random Embeddings",
        "pub_year": "2021",
        "citation": "International Conference on Learning Representations, 2021",
        "num_citations": 10,
        "author_pub_id": "jCNJhFcAAAAJ:hqOjcs7Dif8C"
    },
    {
        "title": "Sample-efficient Surrogate Model for Frequency Response of Linear PDEs using Self-Attentive Complex Polynomials",
        "pub_year": "2023",
        "citation": "arXiv preprint arXiv:2301.02747, 2023",
        "num_citations": 2,
        "author_pub_id": "jCNJhFcAAAAJ:k_IJM867U9cC"
    },
    {
        "title": "Satellite Images and Deep Learning to Identify Discrepancy in Mailing Addresses with Applications to Census 2020 in Houston",
        "pub_year": "2021",
        "citation": "JSM Proceedings, Statistical Learning and Data Science Section. American …, 2021",
        "num_citations": 1,
        "author_pub_id": "jCNJhFcAAAAJ:ULOm3_A8WrAC"
    },
    {
        "title": "Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer",
        "pub_year": "2023",
        "citation": "International Conference on Machine Learning, 2023",
        "num_citations": 76,
        "author_pub_id": "jCNJhFcAAAAJ:7PzlFSSx8tAC"
    },
    {
        "title": "Scatterbrain: Unifying sparse and low-rank attention",
        "pub_year": "2021",
        "citation": "Advances in Neural Information Processing Systems 34, 17413-17426, 2021",
        "num_citations": 133,
        "author_pub_id": "jCNJhFcAAAAJ:Zph67rFs4hoC"
    },
    {
        "title": "Sequoia: Scalable and Robust Speculative Decoding",
        "citation": "The Thirty-eighth Annual Conference on Neural Information Processing Systems, 0",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:ZHo1McVdvXMC"
    },
    {
        "title": "Sequoia: Scalable, robust, and hardware-aware speculative decoding",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2402.12374, 2024",
        "num_citations": 19,
        "author_pub_id": "jCNJhFcAAAAJ:iH-uZ7U-co4C"
    },
    {
        "title": "ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2410.21465, 2024",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:HoB7MX3m0LUC"
    },
    {
        "title": "Sirius: Contextual sparsity with correction for efficient llms",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2409.03856, 2024",
        "num_citations": 1,
        "author_pub_id": "jCNJhFcAAAAJ:ldfaerwXgEUC"
    },
    {
        "title": "Soft Prompt Recovers Compressed LLMs, Transferably",
        "citation": "Forty-first International Conference on Machine Learning, 0",
        "num_citations": 31,
        "author_pub_id": "jCNJhFcAAAAJ:RGFaLdJalmkC"
    },
    {
        "title": "SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2406.02532, 2024",
        "num_citations": 5,
        "author_pub_id": "jCNJhFcAAAAJ:GnPB-g6toBAC"
    },
    {
        "title": "Sub-linear privacy-preserving near-neighbor search",
        "pub_year": "2016",
        "citation": "arXiv preprint arXiv:1612.01835, 2016",
        "num_citations": 27,
        "author_pub_id": "jCNJhFcAAAAJ:qjMakFHDy7sC"
    },
    {
        "title": "Towards structured sparsity in transformers for efficient inference",
        "pub_year": "2023",
        "citation": "Workshop on Efficient Systems for Foundation Models@ ICML2023, 2023",
        "num_citations": 7,
        "author_pub_id": "jCNJhFcAAAAJ:hFOr9nPyWt4C"
    },
    {
        "title": "Triforce: Lossless acceleration of long sequence generation with hierarchical speculative decoding",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2404.11912, 2024",
        "num_citations": 22,
        "author_pub_id": "jCNJhFcAAAAJ:hMod-77fHWUC"
    },
    {
        "title": "Unique entity estimation with application to the Syrian conflict",
        "pub_year": "2018",
        "citation": "The Annals of Applied Statistics 12 (2), 1039-1067, 2018",
        "num_citations": 38,
        "author_pub_id": "jCNJhFcAAAAJ:2osOgNQ5qMEC"
    },
    {
        "title": "VcLLM: Video Codecs are Secretly Tensor Codecs",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2407.00467, 2024",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:lSLTfruPkqcC"
    },
    {
        "title": "Zeroth-Order Fine-Tuning of LLMs with Extreme Sparsity",
        "pub_year": "2024",
        "citation": "arXiv preprint arXiv:2406.02913, 2024",
        "num_citations": 0,
        "author_pub_id": "jCNJhFcAAAAJ:O3NaXMp0MMsC"
    }
]